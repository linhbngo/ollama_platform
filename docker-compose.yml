services:
  base:
    build:
      context: ./docker/base
      tags:
        - "ollama_app:base"
    image: ollama_app:base
    
  jupyter_ollama:
    build:
      context: ./docker/jupyter
      tags:
        - "ollama_jupyter:latest"
    init: true
    image: ollama_jupyter:latest
    ports:
      - "18888:8888" # jupyter
    volumes:
      - ./workspace:/workspace
    expose:
      - "8888"
    hostname: jupyter_ollama 
    container_name: jupyter_ollama
    networks:
      - compute
      
  ollama:
    container_name: ollama
    image: ollama/ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
              count: all
    volumes: # change this to your own external model storage place
      - //e/data/ollama_models:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      OLLAMA_RUN_TIMEOUT: 600
      OLLAMA_REQUEST_TIMEOUT: 600
      OLLAMA_LOAD_TIMEOUT: 600
    networks:
      - compute
  # Launch this if there is no GPU or if you are running on Mac
  ollama-cpu:
    container_name: ollama
    image: ollama/ollama
    volumes:
      - ../ollama_models:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      OLLAMA_RUN_TIMEOUT: 600
      OLLAMA_REQUEST_TIMEOUT: 600
      OLLAMA_LOAD_TIMEOUT: 600
    networks:
      - compute

networks:
  compute:
    name: compute
    driver: bridge
